{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Usage\r\n",
       "r: scala.util.Random = scala.util.Random@45ff33cc\r\n",
       "data: scala.collection.immutable.IndexedSeq[Usage] = Vector(Usage(0,user-Gpi2C,525), Usage(1,user-DgXDi,502), Usage(2,user-M66yO,170), Usage(3,user-xTOn6,913), Usage(4,user-3xGSz,246), Usage(5,user-2aWRN,727), Usage(6,user-EzZY1,65), Usage(7,user-ZlZMZ,935), Usage(8,user-VjxeG,756), Usage(9,user-iqf1P,3), Usage(10,user-91S1q,794), Usage(11,user-qHNj0,501), Usage(12,user-7hb94,460), Usage(13,user-bz0WF,142), Usage(14,user-71nwy,479), Usage(15,user-7GZz1,823), Usage(16,user-1CSk6,140), Usage(17,user-WPzlL,246), Usage(18,user-VaEit,451), Usage(19,user-PSaRq,679), Usage(20,user-0Kkzu,332), Usage(21,user-UN3MG,172), Usage(22,user-KwwER,442), Usage(23,user-ZnltJ,923), Usage(24,user-IRA17,741), Usage(25,user-yNHRT,299), Us...\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Usage(uid: Int, uname: String, usage: Int)\n",
    "\n",
    "val r = new scala.util.Random(42)\n",
    "// Genera 1000 registros \n",
    "val data = for(i <- 0 to 1000)\n",
    "    yield (Usage(i, \"user-\"+r.alphanumeric.take(5).mkString(\"\"), r.nextInt(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsUsage: org.apache.spark.sql.Dataset[Usage] = [uid: int, uname: string ... 1 more field]\r\n",
       "dsUsage2: org.apache.spark.sql.Dataset[Usage] = [uid: int, uname: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dsUsage = data.toDS()\n",
    "val dsUsage2 = spark.createDataset(data)\n",
    "dsUsage.show(10)\n",
    "dsUsage2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+\n",
      "|uid|uname     |usage|\n",
      "+---+----------+-----+\n",
      "|605|user-NL6c4|999  |\n",
      "|561|user-5n2xY|999  |\n",
      "|113|user-nnAXr|999  |\n",
      "|634|user-L0wci|999  |\n",
      "|345|user-QKrVb|996  |\n",
      "+---+----------+-----+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filterWithUsage: (u: Usage)Boolean\r\n",
       "test: org.apache.spark.sql.Dataset[Usage] = [uid: int, uname: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Funciona en el shell\n",
    "dsUsage.filter(d => d.usage > 900)\n",
    "    .orderBy(desc(\"usage\"))\n",
    "    .show(5, false)\n",
    "// definiendo función para filter\n",
    "def filterWithUsage(u: Usage) = u.usage > 900\n",
    "dsUsage.filter(filterWithUsage(_)).orderBy(desc(\"usage\"))\n",
    "/*\n",
    "dsUsage.filter($\"usage\" > 900)\n",
    "    .orderBy(desc(\"usage\"))\n",
    "    .show(5, false)\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "// error en notebook / funciona en shell\n",
    "dsUsage.map(u => {if (u.usage > 750) u.usage * .15 else u.usage * .50}).show(5,false)\n",
    "\n",
    "def computeCostUsage(usage: Int): Double = {\n",
    "    if(usage > 750) usage * 0.15 else usage * 0.50\n",
    "}\n",
    "dsUsage.map(u => {computeCostUsage(u.usage)}).show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class UsageCost\r\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class UsageCost(uid: Int, uname: String, usage: Int, cost: Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeUserCostUsage(u: Usage): UsageCost = {\n",
    "    val v = if(u.usage > 750) u.usage * 0.15 else u.usage * 0.50\n",
    "    UsageCost(u.uid, u.uname, u.usage, v)\n",
    "}\n",
    "\n",
    "dsUsage.map(u => {computeUserCostUsage(u)}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Convertir DataFrame a DataSet de SomeCaseClass\n",
    "// dataframe.as[CaseClass]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Para la mitigación de costes es recomendable evitar el uso excesivo de lambdas, utilizar DSL expressions para evitar la serializacion y deserialización del uso de lambdas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Ejemplo con lambda (a evitar)\\\n",
    "`personDS.filter(x => x.firstName == \"Nell\").distinct().count`\\\n",
    "// Ejemplo con DSL query\\\n",
    "`personDS.filter($\"firstName\" === \"Nell\").distinct().count`\\\n",
    "\n",
    "- Advantages of using lambdas:\n",
    "    - Good for semi-structured data\n",
    "    - Very powerful\n",
    "- Disadvantages:\n",
    "    - Catalyst can't interpret lambdas until runtime. \n",
    "    - Lambdas are opaque to Catalyst. Since it doesn't know what a lambda is doing, it can't move it elsewhere in the processing.\n",
    "    - Jumping between lambdas and the DataFrame query API can hurt performance.\n",
    "    - Working with lambdas means that we need to `deserialize` from Tungsten's format to an object and then reserialize back to Tungsten format when the lambda is done.\n",
    "    \n",
    "If you _have_ to use lambdas, chaining them together can help.\\\n",
    "\n",
    "`personDS\n",
    "  .filter(x => x.birthDate.split(\"-\")(0).toInt > earliestYear) // everyone above 40\n",
    "  .filter($\"salary\" > 80000) // everyone earning more than 80K\n",
    "  .filter(x => x.lastName.startsWith(\"J\")) // last name starts with J\n",
    "  .filter($\"firstName\".startsWith(\"D\")) // first name starts with D\n",
    "  .count()`\n",
    "\n",
    "Same but with DSL, más eficiente, no es necesaria la deserialización y serialización\\\n",
    "`personDS\n",
    "  .filter(year($\"birthDate\") > earliestYear) // everyone above 40\n",
    "  .filter($\"salary\" > 80000) // everyone earning more than 80K\n",
    "  .filter($\"lastName\".startsWith(\"J\")) // last name starts with J\n",
    "  .filter($\"firstName\".startsWith(\"D\")) // first name starts with D\n",
    "  .count()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
